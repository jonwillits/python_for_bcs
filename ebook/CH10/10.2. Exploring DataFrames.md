# 10.2. Exploring Dataframes

## Looking at the DataFrame

Now that we have loaded our dataset, let's start exploring it. One of the first steps in any data analysis begins with 
understanding the nature of the dataset. If you recall, we loaded our dataset in the last section like so:

```python
import pandas as pd
file_name = "predict_mcdi.csv"  # path to the file relative to where the script this code is
header_list = ['word', 'mcdi_score']
mcdi_df = pd.read_csv(file_name)
print(mcdi_df)
```
With the output:
```text
      Age    Word   Lexical_Class     MCDIp   LogFreq    ProKWo
0      16       a  function_words  0.035565  4.432119  0.093588
1      17       a  function_words  0.043956  4.466571  0.106888
2      18       a  function_words  0.079186  4.535028  0.171016
3      19       a  function_words  0.103659  4.580457  0.220025
4      20       a  function_words  0.116788  4.635242  0.243169
...   ...     ...             ...       ...       ...       ...
7495   26  zipper           nouns  0.629834  2.363612  0.571920
7496   27  zipper           nouns  0.610256  2.374748  0.595180
7497   28  zipper           nouns  0.769134  2.385606  0.724979
7498   29  zipper           nouns  0.671717  2.406540  0.668059
7499   30  zipper           nouns  0.820339  2.416641  0.775563

[7500 rows x 6 columns]
```

So what exactly have we created? Let's look at the output of some other print statements:
```python
print(type(mcdi_df))
```
Output: 
```text
<class 'pandas.core.frame.DataFrame'>
```
The output shows that the variable mcdi_df is a pandas DataFrame object. 

We can use .head() to just preview the top of the data:
```python
print(mcdi_df.head(3))
```
Output:
```text
   Age Word   Lexical_Class     MCDIp   LogFreq    ProKWo
0   16    a  function_words  0.035565  4.432119  0.093588
1   17    a  function_words  0.043956  4.466571  0.106888
2   18    a  function_words  0.079186  4.535028  0.171016
```
The number you put inside head specifies how many rows you want to see. The default is 5.

We can also get a simple look at our columns with .dtypes().
```python
print(mcdi_df.dtypes)
```
Output:
```text
Age                int64
Word              object
Lexical_Class     object
MCDIp            float64
LogFreq          float64
ProKWo           float64
dtype: object
```
The .dtypes attribute tells us what the data type of each column is. The "object" datatype is a catch all type that 
might have string data or numbers or both. Remember that when you create the data frame, you can specify what type of 
data type an object can be. This matters because there are certain operations we can perform on data, but only if it 
is a certain type.


We can get a more advanced look at our dataset with the .info() method:
```text
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7500 entries, 0 to 7499
Data columns (total 6 columns):
 #   Column         Non-Null Count  Dtype
---  ------         --------------  -----
 0   Age            7500 non-null   int64
 1   Word           7500 non-null   object
 2   Lexical_Class  7500 non-null   object
 3   MCDIp          7500 non-null   float64
 4   LogFreq        7485 non-null   float64
 5   ProKWo         7485 non-null   float64
dtypes: float64(3), int64(1), object(2)
memory usage: 351.7+ KB
None
```
The .info() method gives us a lot more info about the data frame. It tells us the data structure's data type 
(<class 'pandas.core.frame.DataFrame'>), the number of rows and columns, and the data type of each column. It tells us 
if we have any null (missing) data in either of our columns, and tells us how much memory the dataframe takes up.

Here, the Non-Null Count column in the output shows that columns 0-3 (Age, Word, Lexical_Class, MCDIp) have
750 non-null values, which suggests that these columns have no missing data. However, columns 4-5 (LogFreq nad ProKWo) 
have non-null counts of less 7485, which suggests that these columns have some missing data. 

We will address how handle missing data along with a host of operations in the next section.

## Data Selection

When working with DataFrames, you may want to focus on specific columns in order to calculate mean values or 
to specify values to be plotted in a graph. Pandas allows you to select one or multiple columns easily, resulting in 
a new dataframe with only the specified data.

```python
# Select a single column
mcdi_words = mcdi_df['Word']
print(mcdi_words.head())

# Select multiple columns
mcdi_word_fq = mcdi_df[['Word', 'LogFreq']]
print(mcdi_word_fq.head())
```
Both of these commands are creating new dataframes that have only the subsetted columns in it.

There are other methods for selecting columns using more complex rules. There might be cases when you need to examine 
certain rows. The pandas module provides a simple way to select specific rows or ranges of rows using the `.iloc[]` 
function.
```python
#select the first row
first_row = mcdi_df.iloc[0]
print(first_row)

#select the first 5 rows
first_five_rows = mcdi_df.iloc[0:5]
print(first_five_rows)
```
The .loc[] function works very similarly, but you can specify row or column names instead of index numbers.

In addition to subsetting the dataframe by referencing specific columns or row indices, pandas allows you to subset 
rows based on a specific condition. Say we wanted to only analyze the word statistics of "nouns". We can do so like 
this:
```python
mcdi_noun_data1 = mcdi_df.query('Lexical_Class == "nouns"')
mcdi_noun_data2 = mcdi_df[mcdi_df['Lexical_Class'] == "nouns"]
```
In both cases we specify the column `Lexical_Class` and specify a matching row we wish to subset, `nouns`. 
The first method is producing what is called a "query string" and using that to produce a new dataframe with only the 
data that matches the query. The second method is using a method called boolean indexing. The inner part 
(mcdi_df['Lexical_Class'] == "nouns") return a boolean entry for each row (True or False) corresponding to 
whether the row matches the condition specified. Inserting the resulting boolean dataframe (a single columns of trues 
and falses) into the dataframe itself then gives us back only the rows where the boolean dataframe was true.

Here are some examples of other queries and boolean indexing you might use to subset our current dataset:
```python
# Single Condition: Select rows where word frequency is greater than 2
high_freq = mcdi_df[mcdi_df['LogFreq'] > 2]

# Multiple Conditions (AND): select rows where the word frequency is greater than 2, and the lexical class is 'nouns':
high_freq_nouns = mcdi_df[(mcdi_df['LogFreq'] > 2) & (mcdi_df['Lexical_Class'] == 'nouns')]

#  Multiple Conditions (OR): select rows where the word frequency is greater than 2, and the lexical class is 'nouns':
nouns_or_verbs = mcdi_df[(mcdi_df['Lexical_Class'] == 'nouns') | (mcdi_df['Lexical_Class'] == 'verbs')]

# Negation: Select rows where the lexical class is not 'nouns':
not_nouns = mcdi_df[mcdi_df['Lexical_Class'] != 'nouns']

# Select rows where the lexical class is in a specified list of values:
selected_classes = mcdi_df[mcdi_df['Lexical_Class'].isin(['nouns', 'verbs', 'adjectives'])]
```
You can read more about all the different ways you can filter a dataset here:
https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#data-selection.

Next: [10.3. Pandas Operations](10.3.%20Pandas%20Operations.md)<br>
Previous: [10.1. Loading and Saving Dataframes](10.1.%20Loading%20and%20Saving%20DataFrames.md)
