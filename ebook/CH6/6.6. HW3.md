# 6.7 Homework 3

In Homework 3, you are going to create a python script that tries to predict children's vocabulary development based 
on how frequently children hear words. In other words, "mommy" is one of the first words children say. It is also one 
of the most frequent words children hear. How well can we predict vocabulary development in general from the frequency
of the experiences that children have with words?

In this homework, you are going to make use of a lot of the new stuff you've learned the past two weeks: dictionaries, 
numpy, statistics, and some of the other core python modules. But we also are going to learn one new thing here: project 
organization and management.

## Project organization and management
When we do a scientific project like this, where we have code, data, statistical models, and figures, we don't want
to just throw all that information into a single folder, especially not the same folder you've been putting your other
work in. It's time to get organized. This makes the project easy to move, share and re-use.

So first, create a folder in your bcog200 folder called hw3_lastname_firstname. Then, inside that folder, create four
other folders:
- src: in a project like this, a folder named src is a common place to store python programs and other software you 
write or use for the project.
- data: we want a place to store the data that we use for the project
- models: we want a separate place to store the (statistical) model output that we create as a part of the project. 
Think of data and models as being like the "input" and "output" of the project. They are conceptually distinct, 
and so we want to keep them stored separately.

## Getting the data
To do this we are going to start with two data files, which are available [here](../data/hw3). Download all both files 
and save them in your data folder. These files are:
- mcdi_24.csv: a file with two comma-separated columns specifying a list of 257 nouns, and the percentage of 24-month-olds 
who say each word, according to a survey given to hundreds of parents
- childes_freq_24.csv: a file with two comma-separated columns specifying how frequent those 257 nouns were in a set of 
transcripts of speech to children age 24 months or less in the CHILDES corpus. These numbers are log10 frequencies, meaning 
a word with a score of 1 occurred 10 times in the corpus, a word with score of 2 occurred 100 times, a score of 3 occurred 
1000 times, etc.

## Writing your program
Now, create a file called "predict_child_vocab.py" inside the src folder. That program needs to be purely function 
based, with:

- a main function that 
  - uses sys.argv to receive two input arguments when the program is run and saves those arguments into the variables 
  "mcdi_file_path" and "freq_file_path". In other words, when you run the program, you should type: 
  "python predict_child_vocab.py ../data/mcdi_24.csv ../data/childes_freq_24.csv", because that specifies where those files are, 
  relative to the directory the program is in.
  - calls the load_data() function (described below) twice, each time passing it a filename and getting back a 
  dictionary (one called mcdi_dict, and the other called freq_dict)
  - calls the calculate_stats function, passing it the two data dicts and getting back a stats dict
  - calls the output_stats function, passing it the stats dict

- a "load_data" function that:
  - is passed a filename
  - opens the file, 
  - reads in the data, and stores it in a dictionary with the first column of the data file as the key, and the 
  second column of the data file stored as a float value
  - returns this dictionary to whatever function calls it

- a "convert_dict_to_array" function that
  - is passed a dictionary
  - converts the keys to a list
  - converts the values to a numpy array
  - returns both the list of keys and the array of values to the function that called it

- a "calculate_stats" function that
  - is passed both the mcdi and freq dictionaries
  - creates an empty dictionary called "stats_dict"
  - calls the "convert_dict_to_array" function twice, to convert each dictionary to a numpy array of values
  - uses numpy to calculate the mean and standard deviation of both the mcdi and freq arrays, and stores all four
    values in the stats_dict (with "mcdi_mean", "mcdi_stdev", "freq_mean", and "freq_stdev" as the keys)
  - uses numpy to calculate the regression "line of best fit" for the two arrays, with freq as the "X" and mcdi as 
  the "Y". store the slope and intercept in the stats_dict with m and b as the keys
  - uses numpy to calculate the pearson correlation of the freq and mcdi arrays, and stores it in the stats_dict with
  "r" as the key
  - calculates a "correlation_p_value" by:
    - randomly shuffling both teh freq and mcdi arrays 1000 times
    - calculates what percentage of the time we saw a correlation using random numbers that was equal to or greater than 
    the correlation we actually saw with the real unrandomized data
    - saves this correlation in the stats_dict with "r_simulated_p" as the key
  - returns the stats_dict to the main function

- an "output_model" function that
  - is passed the statistics dictionary,
  - saves the dictionary as a JSON file called "model_results.json" in the models/ folder


Next: 7.0 Classes<br>
Previous: [6.6 Lab 6](6.6.%20Lab%206.md)
